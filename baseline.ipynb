{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0cEcUJutrnk"
      },
      "source": [
        "## Load Dependencies, Model and Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VvvjWcOvKqL"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khEg7uflhntf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel, AutoConfig, AutoModelForQuestionAnswering, AutoModelForSequenceClassification, AutoModelForMultipleChoice\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from sklearn.metrics import classification_report\n",
        "from datasets import load_dataset, DatasetDict\n",
        "import textwrap\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import wandb\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stratify(dataset, yes_max, no_max):\n",
        "  \n",
        "  \" Simple class balancing function w/ shuffling\"\n",
        "\n",
        "  yes_count = 0\n",
        "  no_count = 0\n",
        "\n",
        "  exclude_id = []\n",
        "\n",
        "  for i in range(len(dataset)):\n",
        "\n",
        "    if (dataset[i]['answers'] == \"yes\"): \n",
        "      yes_count+=1\n",
        "      if yes_count > yes_max:\n",
        "        exclude_id.append(i)\n",
        "    \n",
        "    if (dataset[i]['answers'] == \"no\"):   \n",
        "      no_count+=1\n",
        "      if no_count > no_max:\n",
        "        exclude_id.append(i)\n",
        "\n",
        "  dataset = dataset.select(\n",
        "      (\n",
        "          i for i in range(len(dataset)) \n",
        "          if i not in set(exclude_id)\n",
        "      )\n",
        "  )\n",
        "\n",
        "  return dataset.shuffle(seed=42)"
      ],
      "metadata": {
        "id": "0SVVIhCMPpL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKx1J-8lp04p"
      },
      "outputs": [],
      "source": [
        "# Load the labeled BioASQ dataset\n",
        "\n",
        "dataset = load_dataset(\"reginaboateng/Bioasq7b\")['train']\n",
        "\n",
        "# Balance classes\n",
        "\n",
        "dataset_balanced = stratify(dataset, 883, 883)\n",
        "train_dataset = dataset_balanced.select(( i for i in range(0, 1500)))\n",
        "val_dataset = dataset_balanced.select(( i for i in range(1500, 1600)))\n",
        "test_dataset = dataset_balanced.select(( i for i in range(1600, 1766)))\n",
        "\n",
        "# Add numeric label column for all datasets\n",
        "\n",
        "d = {'yes' : 0, 'no': 1}\n",
        "new_column = [d[fd] for fd in train_dataset['answers']] \n",
        "train_dataset = train_dataset.add_column(\"label\", new_column)\n",
        "new_column = [d[fd] for fd in val_dataset['answers']] \n",
        "val_dataset = val_dataset.add_column(\"label\", new_column)\n",
        "new_column = [d[fd] for fd in test_dataset['answers']] \n",
        "test_dataset = test_dataset.add_column(\"label\", new_column)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLUocHE0kcxr"
      },
      "outputs": [],
      "source": [
        "## Check label distributions\n",
        "\n",
        "print(pd.Series(train_dataset['label']).value_counts())\n",
        "print(pd.Series(val_dataset['label']).value_counts())\n",
        "print(pd.Series(test_dataset['label']).value_counts())\n",
        "print(\"\\n\", pd.Series(train_dataset['label']).value_counts(normalize=True))\n",
        "print(pd.Series(val_dataset['label']).value_counts(normalize=True))\n",
        "print(pd.Series(test_dataset['label']).value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtmrjDtZr40G"
      },
      "outputs": [],
      "source": [
        "# Download BioBERT/PubMedBERT model\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
        "model = AutoModelForMultipleChoice.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
        "#tokenizer = AutoTokenizer.from_pretrained('dmis-lab/biobert-v1.1')\n",
        "#model = AutoModelForMultipleChoice.from_pretrained('dmis-lab/biobert-v1.1')\n",
        "\n",
        "#tokenizer = AutoTokenizer.from_pretrained('prajjwal1/bert-tiny')\n",
        "#model = AutoModelForMultipleChoice.from_pretrained('prajjwal1/bert-tiny')\n",
        "#tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "#model = AutoModelForMultipleChoice.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lT2e77VA-9Xz"
      },
      "outputs": [],
      "source": [
        "# View model properties via config file\n",
        "\n",
        "config = AutoConfig.from_pretrained('microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext')\n",
        "#config = AutoConfig.from_pretrained('dmis-lab/biobert-v1.1')\n",
        "#config = AutoConfig.from_pretrained('bert-base-uncased')\n",
        "#config = AutoConfig.from_pretrained('prajjwal1/bert-tiny')\n",
        "\n",
        "config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgnXiB3CcQU6"
      },
      "source": [
        "## Preprocess & Tokenize Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgZHUHL-rRoU"
      },
      "outputs": [],
      "source": [
        "def preprocess(example):\n",
        "\n",
        "  ''' Basic preprocessing & tokenizer function; adapted from https://huggingface.co/docs/transformers/tasks/multiple_choice'''\n",
        "\n",
        "  batch_size = 2\n",
        "  answers = [\"yes\", \"no\"]\n",
        "  context = [[c] * len(answers) for c in example[\"context\"]]\n",
        "  question_headers = example[\"question\"]\n",
        "  \n",
        "  question_answer = [\n",
        "      [f\"{header} {a}\" for a in answers] for i, header in enumerate(question_headers)\n",
        "  ]\n",
        "\n",
        "  #print(\"\\n\", context)\n",
        "  #print(question_answer)\n",
        "\n",
        "  context = sum(context, [])\n",
        "  question_answer = sum(question_answer, [])\n",
        "  \n",
        "  tokenized_examples = tokenizer(context, question_answer, truncation='only_first', max_length=512)\n",
        "  \n",
        "  return {k: [v[i : i + batch_size] for i in range(0, len(v), len(answers))] for k, v in tokenized_examples.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-w_rFGWQ1r9y"
      },
      "outputs": [],
      "source": [
        "# Tokenize the data \n",
        "\n",
        "tokenized_train_dataset = train_dataset.map(preprocess, batched=True)\n",
        "tokenized_val_dataset = val_dataset.map(preprocess, batched=True)\n",
        "tokenized_test_dataset = test_dataset.map(preprocess, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SqckjiIDqE6"
      },
      "outputs": [],
      "source": [
        "# Inspect first element of training \n",
        "\n",
        "print(len(tokenized_train_dataset[0][\"input_ids\"][0]))\n",
        "print(tokenized_train_dataset[0][\"question\"])\n",
        "print(tokenized_train_dataset[0][\"context\"])\n",
        "print(tokenized_train_dataset[0][\"label\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9TULQdaVEob"
      },
      "outputs": [],
      "source": [
        "# Check number of input_id tokens per example \n",
        "\n",
        "for d in tokenized_train_dataset:\n",
        "  print(\"\\nNumber of words in context + question: \", len(d['context'].split()) + len(d['question'].split()))\n",
        "  print(\"Number of input id tokens: \", len(d[\"input_ids\"][0]))\n",
        "  print(\"Number of input id tokens: \", len(d[\"input_ids\"][1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXfIyMLmtgbw"
      },
      "source": [
        "## Finetune model on the BioASQ task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJcW-FPHDjof"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
        "from typing import Optional, Union\n",
        "import torch\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorForMultipleChoice:\n",
        "    \"\"\"\n",
        "    Data collator that will dynamically pad the inputs for multiple choice received. Adapted from https://huggingface.co/docs/transformers/tasks/multiple_choice\n",
        "    \"\"\"\n",
        "\n",
        "    tokenizer: PreTrainedTokenizerBase\n",
        "    padding: Union[bool, str, PaddingStrategy] = True\n",
        "    max_length: Optional[int] = None\n",
        "    pad_to_multiple_of: Optional[int] = None\n",
        "\n",
        "    def __call__(self, features):\n",
        "      \n",
        "      label_name = \"label\" if \"label\" in features[0].keys() else \"label\"\n",
        "      labels = [feature.pop(label_name) for feature in features]\n",
        "      batch_size = len(features)\n",
        "      num_choices = len(features[0][\"input_ids\"])\n",
        "\n",
        "      #print(\"\\nFeatures: \", features)\n",
        "      #print(\"\\nFeature len: \", len(features))\n",
        "      #print(\"num_choices: \", num_choices)\n",
        "      \n",
        "      flattened_features = [\n",
        "          [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features]\n",
        "   \n",
        "      flattened_features = sum(flattened_features, [])\n",
        "\n",
        "      batch = self.tokenizer.pad(\n",
        "          flattened_features,\n",
        "          padding=self.padding,\n",
        "          max_length=self.max_length,\n",
        "          pad_to_multiple_of=self.pad_to_multiple_of,\n",
        "          return_tensors=\"pt\",\n",
        "      )\n",
        "\n",
        "      batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
        "      batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
        "\n",
        "      #print('batch input_id size: ', batch['input_ids'].shape)\n",
        "      #print('batch token_type_id size: ', batch['token_type_ids'].shape)\n",
        "      #print('batch attention_mask size: ', batch['attention_mask'].shape)\n",
        "      #print('batch labels: ', batch['labels'])\n",
        "      #print('labels size: ', len(labels))\n",
        "      #print('\\nBatch: ', batch)\n",
        "\n",
        "      return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xerlrbu8tlgD"
      },
      "outputs": [],
      "source": [
        "# Load evaluation metrics\n",
        "\n",
        "from datasets import load_metric\n",
        "import evaluate\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6ILroMYwZ9U"
      },
      "outputs": [],
      "source": [
        "# Vanilla training setup\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"PubmedBert-QA\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    #save_strategy=\"epoch\",\n",
        "    eval_steps=20,\n",
        "    load_best_model_at_end=True,\n",
        "    learning_rate=  2.86229819276255e-05 ,\n",
        "    per_device_train_batch_size=12,\n",
        "    per_device_eval_batch_size=12,\n",
        "    num_train_epochs= 2,\n",
        "    weight_decay= 0.05,\n",
        "    logging_steps=10,\n",
        "    #fp16=False,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "test_results = trainer.predict(test_dataset=tokenized_test_dataset)\n",
        "test_results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Search"
      ],
      "metadata": {
        "id": "Hn3fIgkIEsUH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtgocsabsgND",
        "outputId": "a226e82e-ce06-4dd9-c6a0-940bb0a54ee8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhk4cd\u001b[0m (\u001b[33mtheotherkhan\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMWAnEyLZlYp"
      },
      "outputs": [],
      "source": [
        "# W&B hyperparameter specification\n",
        "\n",
        "# method\n",
        "sweep_config = {\n",
        "    'method': 'random'\n",
        "}\n",
        "\n",
        "# hyperparameters\n",
        "parameters_dict = {\n",
        "    'epochs': {\n",
        "        'values': [1, 2]\n",
        "        },\n",
        "    'batch_size': {\n",
        "        'values': [4, 8, 12]\n",
        "        },\n",
        "    'learning_rate': {\n",
        "        'distribution': 'log_uniform_values',\n",
        "        'min': 1e-6,\n",
        "        'max': 1e-4\n",
        "    },\n",
        "    'weight_decay': {\n",
        "        'values': [0.05, 0.1, 0.15]\n",
        "    },\n",
        "}\n",
        "\n",
        "metric = {\n",
        "    'name' : 'loss',\n",
        "    'goal' : 'minimize'\n",
        "}\n",
        "\n",
        "sweep_config['metric'] = metric\n",
        "sweep_config['parameters'] = parameters_dict\n",
        "sweep_id = wandb.sweep(sweep_config, project='teacher-biobert-bioasq-narrow-2')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZ3Y8-VUYT0l"
      },
      "outputs": [],
      "source": [
        "# W&B trainer setup\n",
        "\n",
        "preds = []\n",
        "test_accs = []\n",
        "\n",
        "def train(config=None):\n",
        "\n",
        "  with wandb.init(config=config):\n",
        "    # set sweep configuration\n",
        "    config = wandb.config\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "      output_dir=\"/content/wandb/outputs\", \n",
        "      evaluation_strategy=\"steps\",\n",
        "      save_strategy=\"steps\",\n",
        "      eval_steps=20,\n",
        "      load_best_model_at_end=True,\n",
        "      #learning_rate=5e-4,\n",
        "      learning_rate=config.learning_rate,\n",
        "      per_device_train_batch_size=config.batch_size,\n",
        "      per_device_eval_batch_size=config.batch_size,\n",
        "      num_train_epochs=config.epochs,\n",
        "      weight_decay=config.weight_decay,\n",
        "      logging_steps=10,\n",
        "      push_to_hub=False,\n",
        "      report_to=\"wandb\"\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        #model_init=model_init,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_train_dataset,\n",
        "        eval_dataset=tokenized_val_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.agent(sweep_id, train, count=10)"
      ],
      "metadata": {
        "id": "R-RetoGXy7q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Model"
      ],
      "metadata": {
        "id": "TmqpPuGi9Lqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"teacher_model\" # student_model\n",
        "trainer.save_model(\"/content/\" + model_name)\n",
        "model.save_pretrained(\"/content/\" + model_name)\n",
        "!zip -r /content/teacher_model.zip /content/teacher_model"
      ],
      "metadata": {
        "id": "orI6ThFl1Odi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba-C917itl-R"
      },
      "source": [
        "## Evaluate model on the test set\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation using model.predict()\n",
        "test_results = trainer.predict(test_dataset=tokenized_test_dataset)\n",
        "test_results"
      ],
      "metadata": {
        "id": "KiTLPSLNnFq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baPm1Ba_taHp"
      },
      "outputs": [],
      "source": [
        "# # Evaluation using model.evaluate()\n",
        "eval_result = model.evaluate(eval_dataset=tokenized_test_dataset)\n",
        "eval_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjVtj1Qbmn4i"
      },
      "outputs": [],
      "source": [
        "# Manual results framework\n",
        "\n",
        "'''\n",
        "  results = pd.DataFrame()\n",
        "  results['y_true'] = tokenized_test_dataset['label']\n",
        "  results['y_pred'] = y_pred\n",
        "\n",
        "  acc = results[results['y_true'] == results['y_pred']].shape[0]/results.shape[0]\n",
        "  acc\n",
        "'''"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}